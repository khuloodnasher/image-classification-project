{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#ImageDataGenerator\" data-toc-modified-id=\"ImageDataGenerator-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>ImageDataGenerator</a></span></li></ul></li><li><span><a href=\"#Preprocessing-images\" data-toc-modified-id=\"Preprocessing-images-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-image-data-from-the-hierarchical-file-'chest_xray'-using-an-image-datagenerator\" data-toc-modified-id=\"Load-image-data-from-the-hierarchical-file-'chest_xray'-using-an-image-datagenerator-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load image data from the hierarchical file 'chest_xray' using an image datagenerator</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-the-X,y-of-Dataset\" data-toc-modified-id=\"Define-the-X,y-of-Dataset-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Define the X,y of Dataset</a></span></li><li><span><a href=\"#Build-Base-Model\" data-toc-modified-id=\"Build-Base-Model-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Build Base Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Designing-the-CNN\" data-toc-modified-id=\"Designing-the-CNN-1.1.2.1\"><span class=\"toc-item-num\">1.1.2.1&nbsp;&nbsp;</span>Designing the CNN</a></span></li></ul></li><li><span><a href=\"#Pooling-Layer:\" data-toc-modified-id=\"Pooling-Layer:-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Pooling Layer:</a></span></li><li><span><a href=\"#Training-and-Evaluating-the-Model\" data-toc-modified-id=\"Training-and-Evaluating-the-Model-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Training and Evaluating the Model</a></span></li></ul></li><li><span><a href=\"#Severe-OverFitting\" data-toc-modified-id=\"Severe-OverFitting-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Severe OverFitting</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T08:17:28.198329Z",
     "start_time": "2020-06-21T08:17:23.805859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from random import sample\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models,layers\n",
    "from tensorflow.keras.layers import Input, Lambda, Flatten,Activation, Dense, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import models,layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:55:38.589624Z",
     "start_time": "2020-06-19T02:55:38.559889Z"
    }
   },
   "source": [
    "### ImageDataGenerator\n",
    "https://keras.io/api/preprocessing/image/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image data from the hierarchical file 'chest_xray' using an image datagenerator\n",
    "* Load images\n",
    "* define testing,training , validation.\n",
    "* reshape all images to same size of  150 x 150 pixels \n",
    "* chuck data by \"batch_size=20'\n",
    "* scale images through dividing by 255, one pixel=255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T08:17:28.204303Z",
     "start_time": "2020-06-21T08:17:28.200755Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T08:17:28.550781Z",
     "start_time": "2020-06-21T08:17:28.214176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "train_dir =('/Users/khuloodnasher/Documents/Flatiorn/imageclassification/image-classification-project/chest_xray/train')\n",
    "test_dir =('/Users/khuloodnasher/Documents/Flatiorn/imageclassification/image-classification-project/chest_xray/test')\n",
    "validation_dir =('/Users/khuloodnasher/Documents/Flatiorn/imageclassification/image-classification-project/chest_xray/val')\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the X,y of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T08:17:28.571231Z",
     "start_time": "2020-06-21T08:17:28.565775Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "#train_images, train_labels = next(train_generator)\n",
    "#test_images, test_labels = next(test_generator)\n",
    "#val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Base Model \n",
    "##### Designing the CNN\n",
    "###### To design CNN using Keras,we must consider the following:\n",
    "\n",
    "* alternate convolutional and pooling layers.\n",
    "\n",
    "* have later layers having a larger number of parameters in order to detect more abstract patterns.\n",
    "\n",
    "* Add some final dense layers to add a classifier to the convolutional base.\n",
    "\n",
    "* Compile this model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer:\n",
    "Pooling layers goal is to subsample (i.e., shrink) the input image in order to reduce the computational load, the memory usage, and the number of parameters (thereby limiting the risk of overfitting)\n",
    "1. Max pooling: The maximum pixel value of the batch is selected.\n",
    "2. Average pooling: The average value of all the pixels in the batch is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T08:17:28.818731Z",
     "start_time": "2020-06-21T08:17:28.573408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Always start the model with sequebtial function\n",
    "model = models.Sequential()\n",
    "\n",
    "# start adding layers and define the activation function of each layer as' relu', we define images in size 150x150\n",
    "# in keras function for the convolution step is Conv2D\n",
    "\n",
    "# input layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#  First Hidden \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Second Hidden Layer\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#  Third Hidden Layer\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#Change all the layers dimension to vector through Fltten function\n",
    "model.add(layers.Flatten())\n",
    "# Adding the last layer before the output layer\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "# Adding the output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compiling  and Optimizing base model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluating the Model\n",
    " Training deep networks is resource intensive: depending on the size of the data, even a CNN with 3-4 successive \n",
    " \n",
    " convolutional and pooling layers tend to take  hours to train. \n",
    " \n",
    " Using 30 epochs and 8 layers (alternating between convolutional and pooling), our model took about 40 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T09:24:22.094486Z",
     "start_time": "2020-06-21T08:17:28.820436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 139s 1s/step - loss: 0.4719 - acc: 0.7831 - val_loss: 0.9709 - val_acc: 0.6250\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.2400 - acc: 0.9030 - val_loss: 0.4553 - val_acc: 0.7500\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 139s 1s/step - loss: 0.1813 - acc: 0.9325 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.1405 - acc: 0.9414 - val_loss: 0.2662 - val_acc: 0.9375\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 143s 1s/step - loss: 0.1238 - acc: 0.9540 - val_loss: 0.3122 - val_acc: 0.9375\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 138s 1s/step - loss: 0.1160 - acc: 0.9574 - val_loss: 0.4540 - val_acc: 0.8125\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 138s 1s/step - loss: 0.0957 - acc: 0.9640 - val_loss: 0.3139 - val_acc: 0.8125\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.1054 - acc: 0.9560 - val_loss: 0.9952 - val_acc: 0.6250\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 130s 1s/step - loss: 0.0859 - acc: 0.9689 - val_loss: 0.5298 - val_acc: 0.8125\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.0726 - acc: 0.9740 - val_loss: 0.3109 - val_acc: 0.8750\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.0824 - acc: 0.9710 - val_loss: 0.4495 - val_acc: 0.8125\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 131s 1s/step - loss: 0.0703 - acc: 0.9725 - val_loss: 1.2016 - val_acc: 0.6250\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 130s 1s/step - loss: 0.0823 - acc: 0.9679 - val_loss: 0.1752 - val_acc: 0.9375\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.0556 - acc: 0.9800 - val_loss: 1.2379 - val_acc: 0.6250\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 131s 1s/step - loss: 0.0732 - acc: 0.9719 - val_loss: 0.4498 - val_acc: 0.8125\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 130s 1s/step - loss: 0.0688 - acc: 0.9749 - val_loss: 0.3791 - val_acc: 0.8125\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 131s 1s/step - loss: 0.0624 - acc: 0.9815 - val_loss: 0.8214 - val_acc: 0.6875\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 132s 1s/step - loss: 0.0637 - acc: 0.9745 - val_loss: 0.2937 - val_acc: 0.8750\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.0486 - acc: 0.9835 - val_loss: 0.3477 - val_acc: 0.8750\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.0575 - acc: 0.9775 - val_loss: 0.6066 - val_acc: 0.8125\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.0520 - acc: 0.9810 - val_loss: 0.4051 - val_acc: 0.8125\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 135s 1s/step - loss: 0.0490 - acc: 0.9790 - val_loss: 0.3538 - val_acc: 0.8125\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 138s 1s/step - loss: 0.0459 - acc: 0.9855 - val_loss: 0.3392 - val_acc: 0.8125\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.0466 - acc: 0.9850 - val_loss: 0.4501 - val_acc: 0.8125\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 137s 1s/step - loss: 0.0409 - acc: 0.9850 - val_loss: 0.5006 - val_acc: 0.8125\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.0469 - acc: 0.9840 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 136s 1s/step - loss: 0.0376 - acc: 0.9875 - val_loss: 0.4028 - val_acc: 0.7500\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0367 - acc: 0.9880 - val_loss: 0.2963 - val_acc: 0.8750\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.0439 - acc: 0.9840 - val_loss: 0.5486 - val_acc: 0.8125\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.0252 - acc: 0.9920 - val_loss: 0.4283 - val_acc: 0.8125\n"
     ]
    }
   ],
   "source": [
    "# fitting my base_model with training data \n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=100, \n",
    "                              epochs=30, \n",
    "                              validation_data=validation_generator, \n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T09:24:22.099290Z",
     "start_time": "2020-06-21T09:24:22.096654Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train = model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T09:24:22.104870Z",
     "start_time": "2020-06-21T09:24:22.102966Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T09:24:22.110440Z",
     "start_time": "2020-06-21T09:24:22.108436Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T09:24:22.115191Z",
     "start_time": "2020-06-21T09:24:22.112823Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:55:52.320818Z",
     "start_time": "2020-06-21T15:55:51.913344Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f3f5ba43e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.842Z"
    }
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.845Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.849Z"
    }
   },
   "outputs": [],
   "source": [
    "rain_datagen = ImageDataGenerator(rotation_range=40, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, \n",
    "                                                        target_size=(150, 150), \n",
    "                                                        batch_size=32, \n",
    "                                                        class_mode='binary')\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=100, \n",
    "                              epochs=100, \n",
    "                              validation_data=validation_generator, \n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.851Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.854Z"
    }
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training with data augmentation took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                  target_size=(150, 150), \n",
    "                                                  batch_size=20, \n",
    "                                                  class_mode='binary')\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.865Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cnn = Sequential()\n",
    "#Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n",
    "#Pooling\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# 2nd Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "# 2nd Pooling layer\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Flatten the layer\n",
    "cnn.add(Flatten())\n",
    "# Fully Connected Layers\n",
    "cnn.add(Dense(activation = 'relu', units = 512))\n",
    "cnn.add(Dense(activation = 'sigmoid', units = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the Neural network\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.873Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_history = cnn.fit_generator(train_generator,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 25,\n",
    "                         validation_data = val_generator,\n",
    "                         validation_steps = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.875Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train = cnn.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.878Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.881Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T08:17:23.885Z"
    }
   },
   "outputs": [],
   "source": [
    "#results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severe OverFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process\n",
    "1. CNN with small dataset (Acc 71%)\n",
    "2. CNN with data augmentation (Acc 80+%)\n",
    "3. Transfer Learning (Acc 90+%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
